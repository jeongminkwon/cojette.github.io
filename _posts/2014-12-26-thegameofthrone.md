
---
layout: post
title: 얼불노 6권에 대한 베이지안 예측 
---

* 본 포스팅은 http://arxiv.org/abs/1409.5830 의 논문을 요약 번역한 것입니다. 요약/번역 상의 오류에 대한 책임은 저한테 있습니다.

얼불노를 안 읽고 안 봤어도 단번에 씐나게 번역/요약했다. 개념 설명도 꼼꼼하게 되어 있고 무엇보다 내용이 흥미로운 논문. 이런 논문 다이스키. 

#문제 설명

조지 R.R. 마틴의 [얼음과 불의 노래](이하 [얼불노])는 현재 5권까지 나온 상태로, 총 7권으로 마무리될 것이라고 알려져 있으며(이번 크리스마스때 6권이 나온다는 소문이 있었으나 소문에 불과했다. 그래서 이 논문을 읽어보기로 했다), 6권은 [The Winds of Winter] 라는 제목으로 명명될 예정이라고 한다.  이 책은 각 단원별로 한 명의 인물이 내용을 서술하는 식으로 되어 있는데, 책 서두 및 후기를 제외하면 총 24명의 인물이 화자로 등장한다. 이 때  특정 인물 x의 관점에서 서술된 단원을  'x의 POV(point of view)'라 하고, 이 시리즈에서 최소 1개 이상의 POV 단원이 있는 인물을 'POV 인물'이라고 하자.

이 논문의 목적은 현존하는 POV 인물이 남은 두 권-특히 [The Winds of Winter]-에 얼마나 많은 POV 등장인물로 나올 것인지를 예측하는 것이다.  나오지 않은 인물은 다루지 않으며, 이미 죽어나간 인물도 다루지 않는다.

데이터는 프랑스 팬사이트 http://www.lagardedenuit.com/에서 가져온 24 x 5 행렬로 되어 있다. M의 행은 POV 인물에 해당하고 열은 현재 출간된 책 순서로 되어 있다. M의 (i,j)는 책 j에서 인물 i의 POV 단원 개수를 M\_ij로 나타낸 것이다. 이 데이터는 다음 표와 같다.  이 때 제목은 AGOT = A Game of Thrones 처럼 약어로 되어 있다.

![](http://datum.io/wp-content/uploads/2014/12/table1-268x300.jpg)

여기 쓰이는 예측 방법은 크게 점 예측과 구간 예측이 있다.  6권에서 x의 POV 단원의 수를 X_x6 로 나타낸다면, X_x6 = 0이라고 예측할 수 있다.  X\_x6 = 0 이라고 예측하는 것을 '점 예측'이라고 하자. 한편, y 의 POV 단원이 0(너무 적음)일 가능성이나 30(너무 많음)일 가능성은 매우 낮을 것으로 생각할 수 있다. X_y6이라는 점 예측 대신, X_y6의 값이 포함될 것 같은 구간을 나타내는 게 더 나을 수 있다. 이를 '구간 예측'이라고 한다. 예를 들어 X\_y6에 대해 구간 [7,9]는 80% 신뢰 구간에 해당한다고 하면, 이는  80%의 확률로 7 <=X_y6<=9라는 것이다.

또한 확률 예측이 필요하다. 근사값의 구간보다 POV 단원의 수에 대한 모든 가능한 값의 확률 분포를 더 다듬어야 한다. 예를 들어, 확률을 P()로 나타낸다면, P(X\_y6 = 9) = 0.5, P(X\_y6 = 10) = P(X\_y6 = 8) = 0.2, P(X\_y6 = 7) = 0.1, P(X\_y6 = 다른 값) = 0이라고 쓸 수 있다. 이 확률 분포는 X\_y6에 대한 우리의 믿음을 완벽하게 표현한다. 이에 대한 개념은 도박의 원리로 이해할 수 있다. 예를 들어, 만약 우리의 믿음이 옳다면 돈의 반을 X\_y6  = 9에 걸고 나머지 반을 X\_y6 ∈ {7, 8, 10}에 걸 것이다. 이 논문의 목표는 각 POV 인물 y에 대해 이런 확률 분포를 제시하는 것이다.

보통 최고의 예측은 모델링과 상식의 조합에서 나온다고 한다. 여기서는 모델링 관점에 초점을 맞추고 상식적인 면은 다루지 않는다. 우리가 답하고자 하는 것은 "우리가 기존 책에 대해 표 1 외에는 아무런 정보가 없을 때 이후의 책에 대해 무엇을 예측할 수 있을까?"에 대한 것이다.

#모델

책 t에서 인물 i가 등장하는 POV 단원을 X\_it고,  t∈{1,2,3,4,5,6,7}이라고 한다. t\_0에서 t\_1 사이에 특정 인물이 등장하고 다른 시간에는 사라진다고 해보자. 예를 들면 이 인물이 t1에서 죽을 수도 있다. 달리 말해, t<t_0 이고 t>t_1일 때 X_it = 0이다. t_0 <= t <= t_1일 때 POV 단원은 매개변수 λ_i를 갖는 포아송 분포를 따른다고 가정하자.

이 때 t_0과 t_1을 매개변수로 다 사용하려면 불편하니 t_0 = β_i - τ_i고 t_1 = β_i + τ_i인 β_i , τ_i (>=0)을 사용한다.
![](http://datum.io/wp-content/uploads/2014/12/cal1.jpg)


각 캐릭터에 대해 β_i , τ_i,  λ\_i이 다른 캐릭터에 대해 독립적일 수 없으므로 등장인물 수 N에 대해 3N개의  매개변수를 사용하는 모델을 제시할 것이다. 매개변수가 너무 많으면 좋은 예측 모델이 아니므로,  β_i , τ_i,  λ\_i을 '임의 효과'로 가정하여 특정 확률 분포에서 임의 추출해서 가져올 것이다. 이 가정은 서로 다른 등장인물에 대한 매개변수 간에 공통된 부분이 있을 것이라는 데에서 기인한다. 예를 들어 τ\_i 의 일반적인 값은 [A Song of Ice and Fire]에서 평균 등장인물이 얼마나 오래 살았는지를 반영한다.

log(λ_i), β_i , τ\_i를 표준 정규 분포로 가정하는데, 이 때 제약조건이 없으면 λ\_i에 상관없이 β_i = 3; τ_i = 3 과 β_i = 3000; τ\_i = 3000의 값이 동일하게 되어 추론에 영향을 미치므로, β, τ의 범위를 [0,7]이라고 하자. 그러면 전체 모델은 다음과 같이 나타난다.

![](http://datum.io/wp-content/uploads/2014/12/cal2.jpg)

이 때 고정된 i에 대해 X_it는 주어진 β_i , τ_i,  λ_i에 조건부 독립이라고 가정하고, 고정된 t가 있고  i != j일 경우 X_it와 X_jt는 주어진 β_i , τ_i,  λ_i, β_j , τ_j,  λ_j에 조건부 독립이라고 가정한다.

이런 모델을 계층적 모델이라고 하고 μ, σ는 각   β , τ,  λ에 대한 하이퍼파라미터라고 한다.

이때 우도는 다음과 같이 구해진다.

![](http://datum.io/wp-content/uploads/2014/12/cal3.jpg)

이 때 δ_p 는 p가 참일 때 1이고 거짓일 때 0이다.

지역 변수  μ_β ,  μ_τ,  μ_ λ를 사용한 N(0,1000^2)와 단위 변수 σ_β ,  σ_τ,  σ_ λ를 사용한 감마분포 (0.001, 0.001) 의 역 사전 분포를 사용한 베이지안 추론을 사용하여 모델을 최적화 하였다.  모델의 적분 부분은 깁스 샘플링 방식을 사용해서 구했다. λ와 β 부분은 히스토그램 추정 방식을 사용해서 만들어진 주변 분포로부터 추출했다.

알고리즘을 매 회 반복하면서 (μ\_β ,  μ\_τ,  μ\_λ, σ\_β ,  σ\_τ,  σ\_λ)의 값은 정규 분포 이론대로 추출되므로 각 인물 i에 대해 β_i , τ_i,  λ\_i도 이 순서대로 샘플링된다. 그러면 X_i, d+1 과 X_i,d+2는 위의 모델 정의를 통해 구할 수 있다.  이 내용은  R의 truncnorm 패키지를 통해 구현되었다.

#결과

이 모델은 데이터 표의 AFFC의 경우 0이  너무 많아서 제대로 동작하지 않는다. 원래 책 4, 5는 한 권으로 출간될 예정이었으나 이후 2권으로 나누어지면서 이렇게 되었다. 이 부분은 무시하거나, 모델링을 새로 하거나, 데이터를 먼저 손보는 방식으로 접근할 수 있다. 모델링의 경우 이미 매개변수가 충분히 많아서 더 복잡하게 만드는 것은 별로 좋지 않다. 이걸 그냥 무시할 수도 있지만 여기서는 데이터를 먼저 다음과 같이 가공하도록 한다.

![](http://datum.io/wp-content/uploads/2014/12/cal4.jpg)

여기서 c_4와 c_5는 4권과 5권의 단원 숫자다.

알고리즘 반복 시 깁스 샘플링은 번인 테스트로 1000회 돌고 추가로 100000번 돌면서 매회 100번째 샘플을 가져왔다. 그래서 사후 샘플 크기는 1000이었다. 이 샘플 중 임의의 점에서 시작해서 결과가 안정적인 지를 수 회에 걸쳐 확인했다. 여기서 하나의 결과를 나타내면 다음과 같다.  각 표는 6, 7권에서 인물별 POV장의 사후 예측 분포를 나타낸 것이다. (물론 7권의 경우 6권의 내용에 따라 또 달라질 수 있다)

![](http://datum.io/wp-content/uploads/2014/12/table1.jpg)
![](http://datum.io/wp-content/uploads/2014/12/table2.jpg)

이 분포를 그래프로 나타내면 다음과 같다.  분산이 가장 큰 것은 티리온이고, 그 다음이 존 스노우다. 

![](http://datum.io/wp-content/uploads/2014/12/fig1.jpg)
![](http://datum.io/wp-content/uploads/2014/12/fig2.jpg)

얼불노 시리즈에서 가장 화두가 되는 점 중 하나는 주요 인물들이 예상치 못한 순간에 수시로 죽어나간다는 점이다. 따라서 각 인물이 0 POV단원일 확률에도 관심이 생긴다. 이 값은 아래 그래프와 같다. 사후 확률의 샘플을 독립적이라고 봤을 경우, 아래 그래프의 오차 막대는 ±3%에 대한 95% 신뢰구간을 나타낸다. 물론 죽은 인물이 0 POV 단원인 건 자명하지만 역은 참이 아닐 수도 있다는 것을 염두에 두자.

 
![](http://datum.io/wp-content/uploads/2014/12/fig3.jpg)

 

위 그래프의 x축 순서는 6권에서  0 POV단원을 가질 확률 순서로 나타났다. 에다드와 캐털린은 이미 죽었고, 티리온과 에어론은 0일 확률이 동일하다.  존 스노우는 6권에서 1개 이상의 POV 단원을 가질 확률이 0.6 이상이므로 60% 이상의 확률로 살아남을 것임을 알 수 있다.

# 테스트 및 검증

M'에서 사용된 하이퍼파라메터의 사후 값의 중간값에 근접한 값으로  (μ_β ,  μ_τ,  μ_ λ, σ_β ,  σ_τ,  σ_ λ)을 골랐다. μ에는 N(0,0.1^2)의 잡음을 추가하고, 단위 변수 σ에는 exp(Δ) (Δ~N(0,0.01^2))을 곱했다. 100개의 데이터 셋을 사용해서, 총 600개의 신뢰구간이 나온다. 결과는 아래 그래프와 같다. 이를 그대로 테스트한 것이 왼쪽 그래프고, 결과 값이 정수일 경우에 대해서 한 결과 오른쪽과 같이 보다 높은 허용 범위를 나타냈다.  이를 통해 모델 설계는 제대로 되었다는 것을 확인하였다.

![](http://datum.io/wp-content/uploads/2014/12/fig4.jpg)

책 1, 2권만 가지고 이 모델에 테스트를 해서 실제 3권의 값과 비교한 결과는 다음과 같다. 허용 범위는 만족스러웠지만 신뢰 구간이 너무 넓다.

![](http://datum.io/wp-content/uploads/2014/12/fig5.jpg)

 

6권의 예고편과 비교해 봤을 때는 아르야, 아리안느, 빅토리온, 바리스탄이 등장한다. 예측 결과로는 아르야 단원이 1개 이상으로, 결과 표에서는 최소 5개의 아르야 POV장이 있을 것으로 보인다.

#모델의 문제

이 모델에서는 POV 인물이 아니었던 인물은 전혀 다루지 않았으므로, 새로운 인물이 등장하는 것을 파악할 수 없다. 또한 매개변수를 최소로 사용하는 포아종 분포를 가정했다. 보통 개수 추정에는 음의 이항 분포를 더 많이 사용하지만, 모델이 더 복잡해질까봐 사용하지 안않았다. 또한 24개의 값은 표준 분포를 유의미하게 사용하기에는 적은 숫자다. 물론 POV 인물이 더 많았다면 이는 큰 문제가 아니었을 것이다.  게다가 각 값이 독립적일 수 없어서, 하나의 인물의 POV 단원이증가하면 다른 인물의 POV단원은 줄어들 수밖에 없다.

그리고 무엇보다 6권이 출간되기 전까지는 어떤 것도 알 수 없다. 모델의 성능은 6권 출간 후에 다시 파악할 수 있을 것이다.

(http://cojette-wiki.appspot.com/datum.io/%EC%96%BC%EB%B6%88%EB%85%B8_6%EA%B6%8C%EC%97%90_%EB%8C%80%ED%95%9C_%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88_%EC%98%88%EC%B8%A1 에서 가져왔습니다)
