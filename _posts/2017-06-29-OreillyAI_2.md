---
layout: post
title: O’Reilly AI Conference 2일차 후기
---

![image](https://cojette.files.wordpress.com/2017/06/img_6586.jpg?w=2000)

드디어 메인인 세션 발표 날이다.

# Keynotes
키노트는 보통 1주일쯤 후(?) youtube에 무료로 공유되는 것으로 알고 있다. 키노트들 중 흥미로운 것들이 몇 개 있었으니 관심있으신 분들은 한 번 찾아보는 것을 권한다.

## Observations on the era
언제부턴가 데이터 관련 O’Reilly 의 간판이 된(?) Ben Lorica의 오프닝(린 분석 저자와 같이 내 옆 자리에서 술마시던 분이!! (야)). AI 가 흥하고 머신 러닝이 흥하니  Training Data is new-new oil. 이라고 질러주시는데. 네 데이터가 서 말이라도 꿰어야 보배기는 하죠. ~~그런데 정말 그 new oil 드립 어케 안 할 수 없습니까 귀에 딱지 앉겠다.~~

## Tackling the limits of deep learning
Salesforce의 발표. 회사에서 머신 러닝을 잘 활용하기 위해서 필요한 것들에 대한 설명을 듣고 있노라니 여기서는 정말 이런 거 좀 다뤄 본 듯한 느낌이 나는 것이다. 무엇보다 데이터의 supervised learning이 아무래도 유용한데 이거를 하려면 labeling이 필요하다고 이야기하는 것.  ~~(그러니까 데이터에 답을 달아야 하는 게 포인트라니까 말 좀 들어…)~~
그리고 이런 삽질을 통해 아예 Einsten 이라는 Platform 을 만들었더라. 이건 나중에 확인해 봐야겠지만 일단 아인슈타인 캐릭터가 귀여웠다.

## AI Now. For Every Industry.
 NVIDIA 의 발표. **뉴 오일 드립은 이제 정말 지겹다 그만 좀 해주세요.** Training에서 여기서는 Inference로 바뀌었다는 것밖에 없다. 
 뭐 어쨌든 데이터로 꿰어내서 추론을 해야 써먹을 것이다.(하지만 그 전에 구슬인 데이터라도 좀 제대로 모아두었으면 하는 소망이 있다)

그리고 제목답게 여기저기서 사용하는 deep learning 예제를 간단히 들어줬다. 다른 거야 이제 그러려니 치고 전에 Lattice사에 대해 아쉬워했던 것과 같은 data preparation용으로 사용하는 것에 대한 이야기도 나와서 흥미로웠다. 그래 역시 다들 생각하는 건 비슷하구나.

## Can machines spot diseases faster than expert humans?
존스홉킨스 대학의 키노트. 환자 진단을 예로 든다. 환자 진단을 위한 데이터 분석에는 뚜렷한 목적이 있다. 목적을 잡는 것은 굉장히 중요하다. 환자 진단이든 다른 용도든. 그리고 이에 대한 공식을 만들고, 주변의 요인을 동시에 확인하고 파악하며 조기 진단 시스템을 구성한다. X-Ray 사진을 활용할 수는 있지만 이런 거 하나로 증상을 완전히 판단할 수는 없다(이거 판별하는 예제들…보이는가 이 주제가). 여러 가지 요인과 분석을 통해 ‘Bayesian Reasoning’을 하게 되는 것이다.

## The future of AI is now  
IBM의 짧은 키노트. 세상 많은 곳에서 AI(라고 쓰고 Watson이라고 읽는다…; ) 를 쓰고 있다고.

## Machines as thought partners
Collaboration / shared understanding의 중요성을 강조한 키노트. 패턴 분석은 기존부터 많이 연구가 되어 왔지만 이를 제대로 활용하지 못한 것은 분석 결과에서 주변의 맥락 등이 무시되었기 때문에. 따라서 기존의 머신 러닝을 통한 패턴 분석 외에도 reading, reasoning , building a shared understanding 을 통해 공감 가능한 결과를 내야 한다는 것. 나도 늘 주장하던 바라 공감 백배.
매번 분석에서 Why는 데이터로만은 알 수 없다고 외치지만 Why 를 알고자 하는 것이 사람들의 꿈이고 분석의 두 가지 궁극적 목적(미래 예측, 과거 원인 규명) 중 하나지 않던가.

## Building machines that learn and think like people
MIT 에서 발표. 개인적으로 이 키노트 넘나 좋았다고 한다(잠시 운다). 역시나 이제는 패턴 매칭 이상의 것이 필요하다는 이야기로 시작한다. 여기서는 intelligence라고 표현했지만 역시나 상황과 맥락, common sense 에 대한 이야기인 것은 마찬가지. 
그리고는 학습과, 사람들이 처음 보는 그림을 따라 그리는 방식의 유사성을 예를 들면서 이를 causal processs로 보고 이에 대해 **Bayesian Program Learning** 을 적용하는 것을 보여주는데! 짱 멋지다! 어머 이거 내 취향이야!! 라고 생각했다.

# Sessions
그리고는 이후 세션들이 이어졌다. 나는 아무래도 분석가다 보니 Product에 대한 설명이나 개괄적인 방법론 보다는 case study를 선호하는 편인데(사실 이런 게 아니면 컨퍼런스가 아주 큰 의미도 없다. 요즘은 마음만 먹으면 인터넷에서 product나 library 정보는 얻기가 쉬워서), 그런 의미에서는 조금 아쉬운 면도 있었다. 거기다 전반적으로 ‘AI Conference’ 라는 이름 탓인지 sponsor booth들이고 세션들이고 뭔가 어깨에 기운이 잔뜩 들어간 듯한 느낌이라 조금 부담스럽기도 했고, AI startup이 많아짐에 따라 회사 광고(?)가 많을 수밖에 없다는 생각도 들었다. 전반적으로 Strata Conference의 추세도 회사 홍보성 세션이 많아지는 쪽이라고 생각을 했는데, 여기는 정말 아닌 걸 찾는 게 꽤나 힘등렀다.
~~이제는 예전처럼 회사와는 크게 상관없는, 뜬금없는 내용을 미친 척하고 발표하려면 다른 곳을 찾아야 겠다는 생각을 했다.~~

어쨌든 그래도 흥미로운 이야기도 꽤 있었다.다음은 내가 들은 세션들이다.

## From ∞ to 8: Making AI Real
(https://conferences.oreilly.com/artificial-intelligence/ai-ny/public/schedule/detail/59100)
AI를 실무에 적용할 때 주의해야 할 점에 대한 이야기. ‘Technology is the answer. But what was the question?’ 라는 문구에 발표자도 울고 관객도 울고 하늘도 울고 땅도 울고 나도 울었다고 한다.  여러 가지 실제로 고생해 본 것이 느껴지는 발표자의 한숨이 인상적이었다.
AI의 시작은 데이터임을 다시 한 번 강조해 주었고, 실제로 AI를 만들 때 알고리즘 만드는 사람만 뚝딱뚝딱 만드는 게 아니라 하나의 시스템으로, 사용할 사람, 기획자, 디자이너 모두가 모여서 이것을 어디다 쓰고 실제로 어떻게 적용할 지를 같이 이야기하지 않으면 현실과 유리된 예쁜 쓰레기가 만들어진다는, 이미 알지만 여러 사람이 되새겨야 할 좋은 이야기를 들었다.
더불어 실제 아마존 에코의 사용성에 대한 조사( https://www.statista.com/chart/6080/amazon-echo-usage/)가 재미있었다고 한다.

## Beyond the hype: Real AI contributions in industry and engineering
(https://conferences.oreilly.com/artificial-intelligence/ai-ny/public/schedule/detail/59104)
보쉬 AI연구소의 이야기. 자동차의 intelligent assistants 를 만드는 것은 좋은데…회사 자랑만 30분 넘게 하길래 지쳐서 도망나왔다.

## Idea learning: Structuring unstructured data in the enterprise with very little human effort
(https://conferences.oreilly.com/artificial-intelligence/ai-ny/public/schedule/detail/59295)
20분 가량밖에 못 들었다. 아니 이 재밌는 강의이자 오늘 키노트와 더불어 최고의 히트작 강의를 왜 제목을 이렇게 심심하게 지은거죠?!! MIT의 키노트와 이어지는 이야기로, 구글의 그림 맞추기 에서 기름을 그리는 도중에 이 것이 무엇인지를 Bayesian Program learning을 사용해서 추론하는 것에 대한 이야기였다. 짱 흥미로웠다. 
그림 획마다 확률 추론을 하는데 우어어어어. 너무 취향이어서 뭐라 할 말이 없고 나는 **Bayesian program learning**을 공부할 것이다  어딘가에다 써먹을 것이다 써먹고 말 것이다..

## Building game bots using OpenAI’s Gym and Universe
(https://conferences.oreilly.com/artificial-intelligence/ai-ny/public/schedule/detail/59158)
간단한 reinforcement learning을 만들어서도 게임봇을 만들어서 시뮬레이션 할 수 있다. GitHub의 코드를 그대로 설명한 것이니 깃헙 주소 가지고 훑어보면 될 듯 하다. 
Universe 라이브러리 좀 최고고 나도 써보면 웬지 쉽게 게임봇을 만들 수 있을 것 같은 착각이 들었다.

## Humanizing ethnology with EmotionAI
(https://conferences.oreilly.com/artificial-intelligence/ai-ny/public/schedule/detail/59246)
요즘 흥하는 사용자의 감정을 파악해서 광고 효과 분석이나 고객 분석 등에 써먹기 위한 기술을 만드는 회사의 세션. 대표가 TED에도 나왔다더니 발표를 정말 잘 해서 더 인상적이었다. 
일반적으로 감성 분석이라고 하면 10%가 말, 35%가 말의 내용, 55%가 표정과 행동이라고. 그래서 지금까지 기본적인 표정 분석은 가능하지만 말투나 내용을 분석한 후 이를 결합하는 것, 거기다 대부분의 unlabeled data의 labeling, 이런 분석의 활용을 위해서는 실시간 분석에 가까워져야 하고 이를 위해서는 모델 단순화가 필요하다는 점, 간단한 감정 분석 외에 상황 및 보다 자세한 감정 분석이 필요한 것 등 아직 해야 할 숙제가 많다는 점을 꼼꼼하게 짚으면서 인정하는 것도 마음에 들었다.

## Bigger than bots: Machine reading and writing in enterprise
(https://conferences.oreilly.com/artificial-intelligence/ai-ny/public/schedule/detail/59061)
텍스트 분석 관련 내용. 실제로 들어온 내용에 대한 추론을 하고 이를 통해서 대답을 할 수 있게 하는 것을 만들었다. 이를 통해서 고객 응대 등에 활용할 수 있다고. 텍스트를 우르르 읽힌 후 이에 대해서 자동으로 질문을 생성하거나, 주어진 질문에 해당 텍스트 내용을 기반으로 대답하는 것이 인상적이었다. 이 곳의 앞으로의 숙제는 Common sense 추론. 현재로서는 ‘ I poured water from the bottle into the cup until it was full. – What was full? ‘의 질문에 대답하기가 어렵다고.

## Bayesian deep learning in PyMC3
(https://conferences.oreilly.com/artificial-intelligence/ai-ny/public/schedule/detail/59772)
장단점을 가진 deep learning 에 bayesian을 살짝 적용해서 단점을 줄여주는 법. 그리고 이를 PyMC3을 사용해서 구현할 수 있다는 것을 설명함. 
기존의 deep learning의 perceptron에 확률 분포를 적용해서 weight를 넣어주고, 이를 다음 layer전의 prior로 사용하는 방식…인데 자세한 것은 돌려봐야 알겠다(야). 

## 기타

뭐랄까, AI Conference는 AI의 거품 덕분(?)인지 기합이 애매하게 들어간 것 같다. 결국 다들 말하는 것 보면 이전의 Strata와도 크게 다를 것도 없는데.
예전부터 하던 데이터 분석을 ‘빅데이터를 써서 분석해야 한다’라고 했다가 ‘AI로/머신러닝으로 분석하자’ 라고 하지만 하는 일은 늘 비슷한데, 뭔가 되게 부담스럽고 더 피곤해진다.

내일은 더욱 기운내야지. 짠짠.
